{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5ad8c3-6844-43e6-8c77-cd7fc9dc9a89",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m \n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtime\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32e8d3-cf4c-4edc-b3f1-091b9c2e09c4",
   "metadata": {},
   "source": [
    "Create TableGan Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45784b0-f839-4727-94af-eb761baa63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"com_salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662ded7f-7c35-419c-a631-f381ea868c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 909 entries, 0 to 908\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Name              909 non-null    object \n",
      " 1   OttoneuID         909 non-null    int64  \n",
      " 2   FG MajorLeagueID  851 non-null    float64\n",
      " 3   FG MinorLeagueID  902 non-null    object \n",
      " 4   MLB Org           896 non-null    object \n",
      " 5   Position(s)       909 non-null    object \n",
      " 6   Avg Salary        909 non-null    float64\n",
      " 7   Median Salary     909 non-null    float64\n",
      " 8   Min Salary        909 non-null    int64  \n",
      " 9   Max Salary        909 non-null    int64  \n",
      " 10  Last 10           909 non-null    float64\n",
      " 11  Roster%           909 non-null    float64\n",
      " 12  Team              853 non-null    object \n",
      " 13  POS               909 non-null    object \n",
      " 14  ADP               909 non-null    float64\n",
      " 15  rPTS              909 non-null    float64\n",
      " 16  PTS               909 non-null    float64\n",
      " 17  aPOS              909 non-null    float64\n",
      " 18  Dollars           909 non-null    float64\n",
      " 19  Adjusted          909 non-null    float64\n",
      " 20  Cost              262 non-null    float64\n",
      " 21  PlayerId          909 non-null    object \n",
      " 22  value             909 non-null    float64\n",
      "dtypes: float64(13), int64(3), object(7)\n",
      "memory usage: 163.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8cef89-289b-403d-9eb3-ed57c03733a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>OttoneuID</th>\n",
       "      <th>FG MajorLeagueID</th>\n",
       "      <th>FG MinorLeagueID</th>\n",
       "      <th>MLB Org</th>\n",
       "      <th>Position(s)</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Median Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>POS</th>\n",
       "      <th>ADP</th>\n",
       "      <th>rPTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>aPOS</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>23717</td>\n",
       "      <td>20123.0</td>\n",
       "      <td>sa906282</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>10.57</td>\n",
       "      <td>1132.535865</td>\n",
       "      <td>53.429347</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>76.314969</td>\n",
       "      <td>112.280793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>18276</td>\n",
       "      <td>13611.0</td>\n",
       "      <td>sa597889</td>\n",
       "      <td>LAD</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>58.35</td>\n",
       "      <td>58.0</td>\n",
       "      <td>38</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>5.03</td>\n",
       "      <td>1036.172159</td>\n",
       "      <td>40.095221</td>\n",
       "      <td>14.934803</td>\n",
       "      <td>56.030024</td>\n",
       "      <td>82.308998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>33600</td>\n",
       "      <td>19755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Util/SP</td>\n",
       "      <td>56.13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>P/DH</td>\n",
       "      <td>12.73</td>\n",
       "      <td>1038.276653</td>\n",
       "      <td>40.386426</td>\n",
       "      <td>12.178202</td>\n",
       "      <td>53.564628</td>\n",
       "      <td>75.049219</td>\n",
       "      <td>54.0</td>\n",
       "      <td>19755</td>\n",
       "      <td>-0.435372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>18312</td>\n",
       "      <td>15640.0</td>\n",
       "      <td>sa549847</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.5</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1066.255227</td>\n",
       "      <td>44.257902</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>67.143525</td>\n",
       "      <td>93.070498</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15640</td>\n",
       "      <td>17.143525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freddie Freeman</td>\n",
       "      <td>5680</td>\n",
       "      <td>5361.0</td>\n",
       "      <td>sa390291</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1B</td>\n",
       "      <td>50.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1B</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1062.235872</td>\n",
       "      <td>43.701733</td>\n",
       "      <td>13.809086</td>\n",
       "      <td>58.510819</td>\n",
       "      <td>81.663561</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5361</td>\n",
       "      <td>11.510819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  OttoneuID  FG MajorLeagueID FG MinorLeagueID MLB Org  \\\n",
       "0        Juan Soto      23717           20123.0         sa906282     NYY   \n",
       "1     Mookie Betts      18276           13611.0         sa597889     LAD   \n",
       "2    Shohei Ohtani      33600           19755.0              NaN     LAD   \n",
       "3      Aaron Judge      18312           15640.0         sa549847     NYY   \n",
       "4  Freddie Freeman       5680            5361.0         sa390291     LAD   \n",
       "\n",
       "  Position(s)  Avg Salary  Median Salary  Min Salary  Max Salary  ...  \\\n",
       "0          OF       60.31           60.0          34          84  ...   \n",
       "1    2B/SS/OF       58.35           58.0          38          87  ...   \n",
       "2     Util/SP       56.13           56.0          32          88  ...   \n",
       "3          OF       54.17           54.5          33          70  ...   \n",
       "4          1B       50.76           51.0          27          74  ...   \n",
       "\n",
       "        POS    ADP         rPTS        PTS       aPOS    Dollars    Adjusted  \\\n",
       "0     OF/DH  10.57  1132.535865  53.429347  21.885623  76.314969  112.280793   \n",
       "1  2B/SS/OF   5.03  1036.172159  40.095221  14.934803  56.030024   82.308998   \n",
       "2      P/DH  12.73  1038.276653  40.386426  12.178202  53.564628   75.049219   \n",
       "3     OF/DH  11.16  1066.255227  44.257902  21.885623  67.143525   93.070498   \n",
       "4        1B   8.81  1062.235872  43.701733  13.809086  58.510819   81.663561   \n",
       "\n",
       "   Cost  PlayerId      value  \n",
       "0   NaN     20123   0.000000  \n",
       "1   NaN     13611   0.000000  \n",
       "2  54.0     19755  -0.435372  \n",
       "3  50.0     15640  17.143525  \n",
       "4  47.0      5361  11.510819  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d17be43a-b453-4a58-90d8-a224efc68247",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df = df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb15b239-2d20-42c4-a228-5a03d3ebe4c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the number of features\n",
    "number_of_features = orig_df.shape[1]  # Assumes no target variable included; adjust if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba93ca5-4c1e-42af-bf14-b1d12978bb2e",
   "metadata": {},
   "source": [
    "## Step 1: Define the Generator\n",
    "The Generator's role in a GAN is to create synthetic data that is indistinguishable from real data. It learns to do this through the adversarial process with the Discriminator. Here, we define a simple neural network model for the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4620570e-9084-486c-ae8f-a0b4f5ffb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator\n",
    "class Generator(Model):\n",
    "    def __init__(self, z_dim, output_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.dense1 = Dense(128, activation='relu')\n",
    "        self.out = Dense(output_dim, activation='tanh')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.out(x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d9d64-07f3-4dc7-b58f-929363d6c489",
   "metadata": {},
   "source": [
    "## Step 2: Define the Discriminator\n",
    "The Discriminator acts as a classifier that tries to distinguish real data from fake data produced by the Generator. This class is also defined with a simple architecture, consisting of one hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "debf91b7-c7b6-4036-a5d8-7af3f12b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "class Discriminator(Model):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.out = Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        return self.out(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62193b81-1656-49a9-9d0c-9a2d22122998",
   "metadata": {},
   "source": [
    "## Step 3: Define the TableGAN Model\n",
    "Here we integrate the Generator and Discriminator into a complete GAN model. The TableGAN class manages the training loop where both models are trained in an adversarial setup. This structure includes methods for compiling the model and defining the training step, utilizing TensorFlow's capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288bde09-72c2-49f9-b382-1c39c880beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Cellar/jupyterlab/4.1.4/libexec/lib/python3.12/site-packages/keras/src/backend/tensorflow/nn.py:695: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Sigmoid activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'gen_loss': <tf.Tensor: shape=(), dtype=float32, numpy=0.9087286>,\n",
       " 'disc_loss': <tf.Tensor: shape=(), dtype=float32, numpy=1.6692452>}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the TableGAN model\n",
    "class TableGAN(Model):\n",
    "    def __init__(self, input_dim, z_dim):\n",
    "        super(TableGAN, self).__init__()\n",
    "        self.generator = Generator(z_dim, input_dim)\n",
    "        self.discriminator = Discriminator(input_dim)\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer, loss_function):\n",
    "        super(TableGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = tf.shape(real_data)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.z_dim))\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_data = self.generator(random_latent_vectors)\n",
    "            real_output = self.discriminator(real_data)\n",
    "            fake_output = self.discriminator(generated_data)\n",
    "            gen_loss = self.loss_function(tf.ones_like(fake_output), fake_output)\n",
    "            real_loss = self.loss_function(tf.ones_like(real_output), real_output)\n",
    "            fake_loss = self.loss_function(tf.zeros_like(fake_output), fake_output)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "        return {'gen_loss': gen_loss, 'disc_loss': disc_loss}\n",
    "\n",
    "# Setup and initialization\n",
    "input_dim = orig_df.shape[1]  # Number of features from the original DataFrame\n",
    "z_dim = 100  # Latent dimension for the generator\n",
    "table_gan = TableGAN(input_dim=input_dim, z_dim=z_dim)\n",
    "table_gan.compile(\n",
    "    g_optimizer=Adam(1e-4),\n",
    "    d_optimizer=Adam(1e-4),\n",
    "    loss_function=BinaryCrossentropy(from_logits=True)\n",
    ")\n",
    "\n",
    "# Example use case: simulate real data and train\n",
    "real_data = np.random.normal(size=(10, input_dim))  # Simulate real data\n",
    "table_gan.train_step(real_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968ae77-bfbd-4a5c-97dc-a3318f073fc6",
   "metadata": {},
   "source": [
    "## Step 4: Data Loading and Preprocessing\n",
    "Before training the model, it's necessary to load and preprocess your data. This step involves reading a CSV file, detecting numerical and categorical columns, and applying appropriate transformations such as scaling for numerical data and one-hot encoding for categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a69de58-72c7-4a93-add0-ccba17eb1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "data = orig_df  # Ensure orig_df is your DataFrame loaded previously\n",
    "\n",
    "# Selecting numerical and categorical columns\n",
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define preprocessing for numerical columns: impute missing values then scale\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical columns: impute missing values then encode\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply the above transformations appropriately\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_cols),\n",
    "        ('cat', cat_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to your data\n",
    "processed_data = preprocessor.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2ccd-6c26-4be7-b592-71d5b7aa08b6",
   "metadata": {},
   "source": [
    "## Step 5: Initialize and Train the TableGAN Model\n",
    "Finally, initialize the TableGAN model with dimensions derived from the preprocessed data, compile it with chosen optimizers and loss function, and train the model. Here, we specify the learning rates, the loss function, and the training parameters such as the number of epochs and batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "756bde43-54e5-4d56-9196-0f64e19f2eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate synthetic data\n",
    "def generate_synthetic_data(model, num_samples, z_dim):\n",
    "    random_latent_vectors = tf.random.normal(shape=(num_samples, z_dim))\n",
    "    synthetic_data = model.generator(random_latent_vectors).numpy()\n",
    "    return synthetic_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094e1296-3e51-4ac9-bb41-5720c41e2891",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (177836967.py, line 7)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[20], line 7\u001b[0;36m\u001b[0m\n\u001b[0;31m    synthetic_data, elapsed_time = generate_synthetic_data(model = TableGAN, num_samples, z_dim = 100)\u001b[0m\n\u001b[0m                                                                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# User input for the number of synthetic samples\n",
    "num_samples = 1000  # Define number of synthetic examples you want\n",
    "\n",
    "# Generate synthetic data\n",
    "synthetic_data = generate_synthetic_data(model=table_gan, num_samples=num_samples, z_dim=100)\n",
    "\n",
    "# Convert the synthetic data to a pandas DataFrame with original column names\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=original_df.columns)\n",
    "print(\"Generated synthetic data shape:\", synthetic_data.shape)\n",
    "print(\"Synthetic DataFrame head:\", synthetic_df.head())\n",
    "\n",
    "# Display the DataFrame\n",
    "print(\"Shape of synthetic DataFrame:\", synthetic_df.shape)\n",
    "print(synthetic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb608f2-4c15-4de1-bec2-9e79f828b950",
   "metadata": {},
   "source": [
    "## Step 5: Save to CSV\n",
    "Save the synthetic data to a CSV file. This file can be used for further analysis, sharing, or as input to other analytical tools and systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f892469-3057-4eed-b829-3fe14943d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "synthetic_df.to_csv('synthetic_data.csv', index=False)\n",
    "\n",
    "print(\"Synthetic data written to synthetic_data.csv successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cf48c-f359-4595-a8f0-7883a22a8f45",
   "metadata": {},
   "source": [
    "Step 5 Load Datasets: Original and Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de03f85-eac5-4fa9-b328-24319326e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Orig_data = orig_df\n",
    "synthetic_data = synthetic_df\n",
    "\n",
    "\n",
    "print(\"Original Data Columns:\", Orig_data.columns.tolist())\n",
    "print(\"Synthetic Data Columns:\", synthetic_data.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cadc98-9ca7-44fd-b870-8dce49a34c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define Evaluation Functions\n",
    "# Evaluation metrics implementation\n",
    "\n",
    "# Fidelity Metrics\n",
    "# Fidelity Metrics\n",
    "def evaluate_fidelity(real_data, synthetic_data, continuous_columns, categorical_columns):\n",
    "    ks_results = {col: ks_2samp(real_data[col], synthetic_data[col]).statistic for col in continuous_columns}\n",
    "    chi_squared_results = {col: chi2_contingency(pd.crosstab(real_data[col], synthetic_data[col]))[:2] for col in categorical_columns}\n",
    "    return {'KS Test': ks_results, 'Chi-Squared Test': chi_squared_results}\n",
    "\n",
    "# Utility Metrics\n",
    "def evaluate_predictive_performance(real_data, synthetic_data, target_column, test_size=0.3, random_state=42):\n",
    "    X_real = real_data.drop(columns=[target_column])\n",
    "    y_real = real_data[target_column]\n",
    "    X_synthetic = synthetic_data.drop(columns=[target_column])\n",
    "    y_synthetic = synthetic_data[target_column]\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    model.fit(X_synthetic, y_synthetic)\n",
    "    predictions = model.predict(X_real)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_real, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_real, model.predict_proba(X_real)[:, 1]),\n",
    "        'F1 Score': f1_score(y_real, predictions)\n",
    "    }\n",
    "\n",
    "def informativeness_test(real_data, synthetic_data, test_size=0.3, random_state=42):\n",
    "    real_data['is_real'] = 1\n",
    "    synthetic_data['is_real'] = 0\n",
    "    combined_data = pd.concat([real_data, synthetic_data], ignore_index=True)\n",
    "    X = combined_data.drop(columns=['is_real'])\n",
    "    y = combined_data['is_real']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1]),\n",
    "        'F1 Score': f1_score(y_test, predictions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb8006a-8fd2-4f7b-814d-bb592c77aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns to apply metrics\n",
    "continuous_columns = original_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = original_df.select_dtypes(include=['object']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28743071-1e4d-45b4-9aa6-bb465485ae60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate fidelity\n",
    "fidelity_results = evaluate_fidelity(original_df, synthetic_df, continuous_columns, categorical_columns)\n",
    "print(\"Fidelity Results:\", fidelity_results)\n",
    "\n",
    "# Assuming the target column is correctly named and exists in your DataFrame\n",
    "predictive_performance_results = evaluate_predictive_performance(original_df, synthetic_df, 'target_column')\n",
    "print(\"Predictive Performance Results:\", predictive_performance_results)\n",
    "\n",
    "# Informativeness test\n",
    "informativeness_results = informativeness_test(original_df, synthetic_df)\n",
    "print(\"Informativeness Results:\", informativeness_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a486699-5079-41c5-a7e0-a97f41d38792",
   "metadata": {},
   "source": [
    "# Evaluate predictive performance\n",
    "predictive_performance_results = evaluate_predictive_performance(real_data, synthetic_data, 'target_column')\n",
    "print(\"Predictive Performance Results:\", predictive_performance_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
