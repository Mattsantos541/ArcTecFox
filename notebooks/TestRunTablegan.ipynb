{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab5ad8c3-6844-43e6-8c77-cd7fc9dc9a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-26 16:16:43.927226: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b32e8d3-cf4c-4edc-b3f1-091b9c2e09c4",
   "metadata": {},
   "source": [
    "Create TableGan Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a45784b0-f839-4727-94af-eb761baa63dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"com_salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662ded7f-7c35-419c-a631-f381ea868c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 909 entries, 0 to 908\n",
      "Data columns (total 23 columns):\n",
      " #   Column            Non-Null Count  Dtype  \n",
      "---  ------            --------------  -----  \n",
      " 0   Name              909 non-null    object \n",
      " 1   OttoneuID         909 non-null    int64  \n",
      " 2   FG MajorLeagueID  851 non-null    float64\n",
      " 3   FG MinorLeagueID  902 non-null    object \n",
      " 4   MLB Org           896 non-null    object \n",
      " 5   Position(s)       909 non-null    object \n",
      " 6   Avg Salary        909 non-null    float64\n",
      " 7   Median Salary     909 non-null    float64\n",
      " 8   Min Salary        909 non-null    int64  \n",
      " 9   Max Salary        909 non-null    int64  \n",
      " 10  Last 10           909 non-null    float64\n",
      " 11  Roster%           909 non-null    float64\n",
      " 12  Team              853 non-null    object \n",
      " 13  POS               909 non-null    object \n",
      " 14  ADP               909 non-null    float64\n",
      " 15  rPTS              909 non-null    float64\n",
      " 16  PTS               909 non-null    float64\n",
      " 17  aPOS              909 non-null    float64\n",
      " 18  Dollars           909 non-null    float64\n",
      " 19  Adjusted          909 non-null    float64\n",
      " 20  Cost              262 non-null    float64\n",
      " 21  PlayerId          909 non-null    object \n",
      " 22  value             909 non-null    float64\n",
      "dtypes: float64(13), int64(3), object(7)\n",
      "memory usage: 163.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad8cef89-289b-403d-9eb3-ed57c03733a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>OttoneuID</th>\n",
       "      <th>FG MajorLeagueID</th>\n",
       "      <th>FG MinorLeagueID</th>\n",
       "      <th>MLB Org</th>\n",
       "      <th>Position(s)</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Median Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>POS</th>\n",
       "      <th>ADP</th>\n",
       "      <th>rPTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>aPOS</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>23717</td>\n",
       "      <td>20123.0</td>\n",
       "      <td>sa906282</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>10.57</td>\n",
       "      <td>1132.535865</td>\n",
       "      <td>53.429347</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>76.314969</td>\n",
       "      <td>112.280793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>18276</td>\n",
       "      <td>13611.0</td>\n",
       "      <td>sa597889</td>\n",
       "      <td>LAD</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>58.35</td>\n",
       "      <td>58.0</td>\n",
       "      <td>38</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>5.03</td>\n",
       "      <td>1036.172159</td>\n",
       "      <td>40.095221</td>\n",
       "      <td>14.934803</td>\n",
       "      <td>56.030024</td>\n",
       "      <td>82.308998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>33600</td>\n",
       "      <td>19755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Util/SP</td>\n",
       "      <td>56.13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>P/DH</td>\n",
       "      <td>12.73</td>\n",
       "      <td>1038.276653</td>\n",
       "      <td>40.386426</td>\n",
       "      <td>12.178202</td>\n",
       "      <td>53.564628</td>\n",
       "      <td>75.049219</td>\n",
       "      <td>54.0</td>\n",
       "      <td>19755</td>\n",
       "      <td>-0.435372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>18312</td>\n",
       "      <td>15640.0</td>\n",
       "      <td>sa549847</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.5</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1066.255227</td>\n",
       "      <td>44.257902</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>67.143525</td>\n",
       "      <td>93.070498</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15640</td>\n",
       "      <td>17.143525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freddie Freeman</td>\n",
       "      <td>5680</td>\n",
       "      <td>5361.0</td>\n",
       "      <td>sa390291</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1B</td>\n",
       "      <td>50.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1B</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1062.235872</td>\n",
       "      <td>43.701733</td>\n",
       "      <td>13.809086</td>\n",
       "      <td>58.510819</td>\n",
       "      <td>81.663561</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5361</td>\n",
       "      <td>11.510819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  OttoneuID  FG MajorLeagueID FG MinorLeagueID MLB Org  \\\n",
       "0        Juan Soto      23717           20123.0         sa906282     NYY   \n",
       "1     Mookie Betts      18276           13611.0         sa597889     LAD   \n",
       "2    Shohei Ohtani      33600           19755.0              NaN     LAD   \n",
       "3      Aaron Judge      18312           15640.0         sa549847     NYY   \n",
       "4  Freddie Freeman       5680            5361.0         sa390291     LAD   \n",
       "\n",
       "  Position(s)  Avg Salary  Median Salary  Min Salary  Max Salary  ...  \\\n",
       "0          OF       60.31           60.0          34          84  ...   \n",
       "1    2B/SS/OF       58.35           58.0          38          87  ...   \n",
       "2     Util/SP       56.13           56.0          32          88  ...   \n",
       "3          OF       54.17           54.5          33          70  ...   \n",
       "4          1B       50.76           51.0          27          74  ...   \n",
       "\n",
       "        POS    ADP         rPTS        PTS       aPOS    Dollars    Adjusted  \\\n",
       "0     OF/DH  10.57  1132.535865  53.429347  21.885623  76.314969  112.280793   \n",
       "1  2B/SS/OF   5.03  1036.172159  40.095221  14.934803  56.030024   82.308998   \n",
       "2      P/DH  12.73  1038.276653  40.386426  12.178202  53.564628   75.049219   \n",
       "3     OF/DH  11.16  1066.255227  44.257902  21.885623  67.143525   93.070498   \n",
       "4        1B   8.81  1062.235872  43.701733  13.809086  58.510819   81.663561   \n",
       "\n",
       "   Cost  PlayerId      value  \n",
       "0   NaN     20123   0.000000  \n",
       "1   NaN     13611   0.000000  \n",
       "2  54.0     19755  -0.435372  \n",
       "3  50.0     15640  17.143525  \n",
       "4  47.0      5361  11.510819  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d17be43a-b453-4a58-90d8-a224efc68247",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_df= df[['ADP', 'Avg Salary', 'Median Salary', 'Min Salary', 'Max Salary', 'rPTS', 'PTS', 'Dollars']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb15b239-2d20-42c4-a228-5a03d3ebe4c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ADP</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Median Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>rPTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>Dollars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.57</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>1132.535865</td>\n",
       "      <td>53.429347</td>\n",
       "      <td>76.314969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.03</td>\n",
       "      <td>58.35</td>\n",
       "      <td>58.0</td>\n",
       "      <td>38</td>\n",
       "      <td>87</td>\n",
       "      <td>1036.172159</td>\n",
       "      <td>40.095221</td>\n",
       "      <td>56.030024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12.73</td>\n",
       "      <td>56.13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>1038.276653</td>\n",
       "      <td>40.386426</td>\n",
       "      <td>53.564628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.16</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.5</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>1066.255227</td>\n",
       "      <td>44.257902</td>\n",
       "      <td>67.143525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.81</td>\n",
       "      <td>50.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>1062.235872</td>\n",
       "      <td>43.701733</td>\n",
       "      <td>58.510819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ADP  Avg Salary  Median Salary  Min Salary  Max Salary         rPTS  \\\n",
       "0  10.57       60.31           60.0          34          84  1132.535865   \n",
       "1   5.03       58.35           58.0          38          87  1036.172159   \n",
       "2  12.73       56.13           56.0          32          88  1038.276653   \n",
       "3  11.16       54.17           54.5          33          70  1066.255227   \n",
       "4   8.81       50.76           51.0          27          74  1062.235872   \n",
       "\n",
       "         PTS    Dollars  \n",
       "0  53.429347  76.314969  \n",
       "1  40.095221  56.030024  \n",
       "2  40.386426  53.564628  \n",
       "3  44.257902  67.143525  \n",
       "4  43.701733  58.510819  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba93ca5-4c1e-42af-bf14-b1d12978bb2e",
   "metadata": {},
   "source": [
    "## Step 1: Define the Generator\n",
    "The Generator's role in a GAN is to create synthetic data that is indistinguishable from real data. It learns to do this through the adversarial process with the Discriminator. Here, we define a simple neural network model for the\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4620570e-9084-486c-ae8f-a0b4f5ffb140",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Generator\n",
    "class Generator(Model):\n",
    "    def __init__(self, z_dim):\n",
    "        super(Generator, self).__init__()\n",
    "        self.z_dim = z_dim  # Store the dimension as an attribute\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.out = layers.Dense(z_dim, activation='tanh')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.out(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "664d9d64-07f3-4dc7-b58f-929363d6c489",
   "metadata": {},
   "source": [
    "## Step 2: Define the Discriminator\n",
    "The Discriminator acts as a classifier that tries to distinguish real data from fake data produced by the Generator. This class is also defined with a simple architecture, consisting of one hidden layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "debf91b7-c7b6-4036-a5d8-7af3f12b6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Discriminator\n",
    "class Discriminator(Model):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.dense1 = layers.Dense(64, activation='relu')\n",
    "        self.out = layers.Dense(1, activation='sigmoid')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.dense1(x)\n",
    "        return self.out(x)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62193b81-1656-49a9-9d0c-9a2d22122998",
   "metadata": {},
   "source": [
    "## Step 3: Define the TableGAN Model\n",
    "Here we integrate the Generator and Discriminator into a complete GAN model. The TableGAN class manages the training loop where both models are trained in an adversarial setup. This structure includes methods for compiling the model and defining the training step, utilizing TensorFlow's capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "288bde09-72c2-49f9-b382-1c39c880beb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3809538683.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[11], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    super(T=tablegan, self).__init__()\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "# Define the TableGAN model\n",
    "class tablegan(Model):\n",
    "    def __init__(self, input_dim, z_dim):\n",
    "        super(T=tablegan, self).__init__()\n",
    "        self.generator = Generator(z_dim)\n",
    "        self.discriminator = Discriminator(input_dim)\n",
    "\n",
    "    def compile(self, g_optimizer, d_optimizer, loss_function):\n",
    "        super(TableGAN, self).compile()\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.loss_function = loss_function\n",
    "\n",
    "    def train_step(self, real_data):\n",
    "        batch_size = tf.shape(real_data)[0]\n",
    "        # Use the stored z_dim directly from the generator\n",
    "        z_dim = self.generator.z_dim\n",
    "\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, z_dim))\n",
    "\n",
    "        with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "            generated_data = self.generator(random_latent_vectors)\n",
    "            real_output = self.discriminator(real_data)\n",
    "            fake_output = self.discriminator(generated_data)\n",
    "\n",
    "            gen_loss = self.loss_function(tf.ones_like(fake_output), fake_output)\n",
    "            real_loss = self.loss_function(tf.ones_like(real_output), real_output)\n",
    "            fake_loss = self.loss_function(tf.zeros_like(fake_output), fake_output)\n",
    "            disc_loss = real_loss + fake_loss\n",
    "\n",
    "        gradients_of_generator = gen_tape.gradient(gen_loss, self.generator.trainable_variables)\n",
    "        gradients_of_discriminator = disc_tape.gradient(disc_loss, self.discriminator.trainable_variables)\n",
    "\n",
    "        self.g_optimizer.apply_gradients(zip(gradients_of_generator, self.generator.trainable_variables))\n",
    "        self.d_optimizer.apply_gradients(zip(gradients_of_discriminator, self.discriminator.trainable_variables))\n",
    "\n",
    "        return {'gen_loss': gen_loss, 'disc_loss': disc_loss}\n",
    "\n",
    "# Example of setting up optimizers and loss functions\n",
    "g_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "d_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "loss_function = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "# Create a TableGAN instance and compile\n",
    "table_gan = tablegan(input_dim=20, z_dim=100)\n",
    "table_gan.compile(g_optimizer=g_optimizer, d_optimizer=d_optimizer, loss_function=loss_function)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2968ae77-bfbd-4a5c-97dc-a3318f073fc6",
   "metadata": {},
   "source": [
    "## Step 4: Data Loading and Preprocessing\n",
    "Before training the model, it's necessary to load and preprocess your data. This step involves reading a CSV file, detecting numerical and categorical columns, and applying appropriate transformations such as scaling for numerical data and one-hot encoding for categorical data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a69de58-72c7-4a93-add0-ccba17eb1615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess the data\n",
    "data = orig_df  # Ensure orig_df is your DataFrame loaded previously\n",
    "\n",
    "# Selecting numerical and categorical columns\n",
    "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Define preprocessing for numerical columns: impute missing values then scale\n",
    "num_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Define preprocessing for categorical columns: impute missing values then encode\n",
    "cat_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "# Create a ColumnTransformer to apply the above transformations appropriately\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_pipeline, numerical_cols),\n",
    "        ('cat', cat_pipeline, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# Apply transformations to your data\n",
    "processed_data = preprocessor.fit_transform(data)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ab2ccd-6c26-4be7-b592-71d5b7aa08b6",
   "metadata": {},
   "source": [
    "## Step 5: Initialize and Train the TableGAN Model\n",
    "Finally, initialize the TableGAN model with dimensions derived from the preprocessed data, compile it with chosen optimizers and loss function, and train the model. Here, we specify the learning rates, the loss function, and the training parameters such as the number of epochs and batch size.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "756bde43-54e5-4d56-9196-0f64e19f2eeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tablegan' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Generate synthetic data\u001b[39;00m\n\u001b[1;32m      8\u001b[0m random_latent_vectors \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mnormal(shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1000\u001b[39m, z_dim))  \u001b[38;5;66;03m# Generate 1000 samples\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m synthetic_data \u001b[38;5;241m=\u001b[39m \u001b[43mtablegan\u001b[49m\u001b[38;5;241m.\u001b[39mgenerator(random_latent_vectors)\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# End timing\u001b[39;00m\n\u001b[1;32m     12\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tablegan' is not defined"
     ]
    }
   ],
   "source": [
    "# Assuming z_dim is defined earlier as used in initializing TableGAN\n",
    "z_dim = 50  # Update this if it's different\n",
    "\n",
    "# Start timing the generation process\n",
    "start_time = time.time()\n",
    "\n",
    "# Generate synthetic data\n",
    "random_latent_vectors = tf.random.normal(shape=(1000, z_dim))  # Generate 1000 samples\n",
    "synthetic_data = tablegan.generator(random_latent_vectors).numpy()\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate and print the elapsed time\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"Synthetic data generation completed in {elapsed_time:.2f} seconds.\")\n",
    "\n",
    "# Convert the synthetic data to a pandas DataFrame\n",
    "synthetic_df = pd.DataFrame(synthetic_data, columns=[f\"feature_{i+1}\" for i in range(synthetic_data.shape[1])])\n",
    "\n",
    "# Print the DataFrame shape and head to verify\n",
    "print(\"Shape of synthetic DataFrame:\", synthetic_df.shape)\n",
    "print(\"First few rows of the synthetic DataFrame:\")\n",
    "print(synthetic_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdb608f2-4c15-4de1-bec2-9e79f828b950",
   "metadata": {},
   "source": [
    "## Step 5: Save to CSV\n",
    "Save the synthetic data to a CSV file. This file can be used for further analysis, sharing, or as input to other analytical tools and systems.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f892469-3057-4eed-b829-3fe14943d6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to CSV\n",
    "synthetic_df.to_csv('synthetic_data.csv', index=False)\n",
    "\n",
    "print(\"Synthetic data written to synthetic_data.csv successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d4cf48c-f359-4595-a8f0-7883a22a8f45",
   "metadata": {},
   "source": [
    "Step 5 Load Datasets: Original and Synthetic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de03f85-eac5-4fa9-b328-24319326e2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Orig_data = orig_df\n",
    "#synthetic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62cadc98-9ca7-44fd-b870-8dce49a34c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Define Evaluation Functions\n",
    "# Evaluation metrics implementation\n",
    "\n",
    "# Fidelity Metrics\n",
    "def evaluate_fidelity(real_data, synthetic_data, continuous_columns, categorical_columns):\n",
    "    ks_results = {col: ks_2samp(real_data[col], synthetic_data[col]) for col in continuous_columns}\n",
    "    chi_squared_results = {col: chi2_contingency(pd.crosstab(real_data[col], synthetic_data[col]))[:2] for col in categorical_columns}\n",
    "    return {'KS Test': ks_results, 'Chi-Squared Test': chi_squared_results}\n",
    "\n",
    "# Utility Metrics\n",
    "def evaluate_predictive_performance(real_data, synthetic_data, target_column, test_size=0.3, random_state=42):\n",
    "    X_real = real_data.drop(columns=[target_column])\n",
    "    y_real = real_data[target_column]\n",
    "    X_train_real, X_test_real, y_train_real, y_test_real = train_test_split(X_real, y_real, test_size=test_size, random_state=random_state)\n",
    "    X_synthetic = synthetic_data.drop(columns=[target_column])\n",
    "    y_synthetic = synthetic_data[target_column]\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    model.fit(X_synthetic, y_synthetic)\n",
    "    predictions = model.predict(X_test_real)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test_real, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_test_real, model.predict_proba(X_test_real)[:, 1]),\n",
    "        'F1 Score': f1_score(y_test_real, predictions)\n",
    "    }\n",
    "\n",
    "def informativeness_test(real_data, synthetic_data, test_size=0.3, random_state=42):\n",
    "    real_data['is_real'] = 1\n",
    "    synthetic_data['is_real'] = 0\n",
    "    combined_data = pd.concat([real_data, synthetic_data], ignore_index=True)\n",
    "    X = combined_data.drop(columns=['is_real'])\n",
    "    y = combined_data['is_real']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1]),\n",
    "        'F1 Score': f1_score(y_test, predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28743071-1e4d-45b4-9aa6-bb465485ae60",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'real_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#Evaluate Fidelity\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Identify columns to apply metrics\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m continuous_columns \u001b[38;5;241m=\u001b[39m \u001b[43mreal_data\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint64\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfloat64\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      4\u001b[0m categorical_columns \u001b[38;5;241m=\u001b[39m real_data\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Evaluate fidelity\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'real_data' is not defined"
     ]
    }
   ],
   "source": [
    "#Evaluate Fidelity\n",
    "# Identify columns to apply metrics\n",
    "continuous_columns = real_data.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_columns = real_data.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "# Evaluate fidelity\n",
    "fidelity_results = evaluate_fidelity(real_data, synthetic_data, continuous_columns, categorical_columns)\n",
    "print(\"Fidelity Results:\", fidelity_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ade6c2a-0f1e-4c13-bd3e-11a1d030e4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate predictive performance\n",
    "predictive_performance_results = evaluate_predictive_performance(real_data, synthetic_data, 'target_column')\n",
    "print(\"Predictive Performance Results:\", predictive_performance_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd60442d-8c15-4262-82d9-cc44f3b895e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate informativeness\n",
    "informativeness_results = informativeness_test(real_data, synthetic_data)\n",
    "print(\"Informativeness Results:\", informativeness_results)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
