{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d18610c-45c4-4e3a-9bd0-d01bd4c77d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74b57e5a-0634-4888-a923-2345986e6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"MKL_THREADING_LAYER\"] = \"TBB\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "81b37cd8-9ee9-4ece-a0c7-a1990910a805",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['CTGAN',\n",
       " 'TVAE',\n",
       " '__all__',\n",
       " '__author__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__email__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '__version__',\n",
       " 'data_sampler',\n",
       " 'data_transformer',\n",
       " 'demo',\n",
       " 'load_demo',\n",
       " 'synthesizers']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ctgan\n",
    "dir(ctgan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80133ceb-5aa0-41bc-a36c-c5196c39eb1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ctgan import CTGAN\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.stats import ks_2samp, chi2_contingency\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "925b8f53-77be-4b8a-9662-01b450de034b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"com_salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a658589-8e40-4f30-bf36-0b0110cf3f60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>OttoneuID</th>\n",
       "      <th>FG MajorLeagueID</th>\n",
       "      <th>FG MinorLeagueID</th>\n",
       "      <th>MLB Org</th>\n",
       "      <th>Position(s)</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Median Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>POS</th>\n",
       "      <th>ADP</th>\n",
       "      <th>rPTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>aPOS</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>23717</td>\n",
       "      <td>20123.0</td>\n",
       "      <td>sa906282</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>10.57</td>\n",
       "      <td>1132.535865</td>\n",
       "      <td>53.429347</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>76.314969</td>\n",
       "      <td>112.280793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>18276</td>\n",
       "      <td>13611.0</td>\n",
       "      <td>sa597889</td>\n",
       "      <td>LAD</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>58.35</td>\n",
       "      <td>58.0</td>\n",
       "      <td>38</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>5.03</td>\n",
       "      <td>1036.172159</td>\n",
       "      <td>40.095221</td>\n",
       "      <td>14.934803</td>\n",
       "      <td>56.030024</td>\n",
       "      <td>82.308998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>33600</td>\n",
       "      <td>19755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Util/SP</td>\n",
       "      <td>56.13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>P/DH</td>\n",
       "      <td>12.73</td>\n",
       "      <td>1038.276653</td>\n",
       "      <td>40.386426</td>\n",
       "      <td>12.178202</td>\n",
       "      <td>53.564628</td>\n",
       "      <td>75.049219</td>\n",
       "      <td>54.0</td>\n",
       "      <td>19755</td>\n",
       "      <td>-0.435372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>18312</td>\n",
       "      <td>15640.0</td>\n",
       "      <td>sa549847</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.5</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1066.255227</td>\n",
       "      <td>44.257902</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>67.143525</td>\n",
       "      <td>93.070498</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15640</td>\n",
       "      <td>17.143525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freddie Freeman</td>\n",
       "      <td>5680</td>\n",
       "      <td>5361.0</td>\n",
       "      <td>sa390291</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1B</td>\n",
       "      <td>50.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1B</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1062.235872</td>\n",
       "      <td>43.701733</td>\n",
       "      <td>13.809086</td>\n",
       "      <td>58.510819</td>\n",
       "      <td>81.663561</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5361</td>\n",
       "      <td>11.510819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  OttoneuID  FG MajorLeagueID FG MinorLeagueID MLB Org  \\\n",
       "0        Juan Soto      23717           20123.0         sa906282     NYY   \n",
       "1     Mookie Betts      18276           13611.0         sa597889     LAD   \n",
       "2    Shohei Ohtani      33600           19755.0              NaN     LAD   \n",
       "3      Aaron Judge      18312           15640.0         sa549847     NYY   \n",
       "4  Freddie Freeman       5680            5361.0         sa390291     LAD   \n",
       "\n",
       "  Position(s)  Avg Salary  Median Salary  Min Salary  Max Salary  ...  \\\n",
       "0          OF       60.31           60.0          34          84  ...   \n",
       "1    2B/SS/OF       58.35           58.0          38          87  ...   \n",
       "2     Util/SP       56.13           56.0          32          88  ...   \n",
       "3          OF       54.17           54.5          33          70  ...   \n",
       "4          1B       50.76           51.0          27          74  ...   \n",
       "\n",
       "        POS    ADP         rPTS        PTS       aPOS    Dollars    Adjusted  \\\n",
       "0     OF/DH  10.57  1132.535865  53.429347  21.885623  76.314969  112.280793   \n",
       "1  2B/SS/OF   5.03  1036.172159  40.095221  14.934803  56.030024   82.308998   \n",
       "2      P/DH  12.73  1038.276653  40.386426  12.178202  53.564628   75.049219   \n",
       "3     OF/DH  11.16  1066.255227  44.257902  21.885623  67.143525   93.070498   \n",
       "4        1B   8.81  1062.235872  43.701733  13.809086  58.510819   81.663561   \n",
       "\n",
       "   Cost  PlayerId      value  \n",
       "0   NaN     20123   0.000000  \n",
       "1   NaN     13611   0.000000  \n",
       "2  54.0     19755  -0.435372  \n",
       "3  50.0     15640  17.143525  \n",
       "4  47.0      5361  11.510819  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dc58e30-c6ca-4b7e-b949-1cb2372f207e",
   "metadata": {},
   "source": [
    "\n",
    "# Assuming `orig_df` is your original DataFrame with the actual data\n",
    "# Example DataFrame (replace with your actual DataFrame)\n",
    "orig_df = pd.DataFrame({\n",
    "    'OttoneuID': [1, 2, 3, 4, 5],\n",
    "    'FG MajorLeagueID': [1001, 1002, 1003, 1004, 1005],\n",
    "    'Avg Salary': [10, 20, 30, 40, 50],\n",
    "    'Median Salary': [15, 25, 35, 45, 55],\n",
    "    'Min Salary': [5, 10, 15, 20, 25],\n",
    "    'Max Salary': [20, 30, 40, 50, 60],\n",
    "    'Last 10': [7, 8, 9, 10, 11],\n",
    "    'Roster%': [60, 70, 80, 90, 100],\n",
    "    'ADP': [1, 2, 3, 4, 5],\n",
    "    'rPTS': [100, 200, 300, 400, 500],\n",
    "    'PTS': [150, 250, 350, 450, 550],\n",
    "    'aPOS': [1, 2, 3, 4, 5],\n",
    "    'Dollars': [10, 20, 30, 40, 50],\n",
    "    'Adjusted': [5, 10, 15, 20, 25],\n",
    "    'Cost': [2, 4, 6, 8, 10],\n",
    "    'value': [8, 16, 24, 32, 40],\n",
    "    'Name': ['Player1', 'Player2', 'Player3', 'Player4', 'Player5'],\n",
    "    'FG MinorLeagueID': ['ID1', 'ID2', 'ID3', 'ID4', 'ID5'],\n",
    "    'MLB Org': ['TeamA', 'TeamB', 'TeamC', 'TeamD', 'TeamE'],\n",
    "    'Position(s)': ['Pos1', 'Pos2', 'Pos3', 'Pos4', 'Pos5'],\n",
    "    'Team': ['Team1', 'Team2', 'Team3', 'Team4', 'Team5'],\n",
    "    'POS': ['POS1', 'POS2', 'POS3', 'POS4', 'POS5'],\n",
    "    'PlayerId': ['P1', 'P2', 'P3', 'P4', 'P5']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "94bbe831-bd2a-464d-a6aa-5fc72eb3b9c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>OttoneuID</th>\n",
       "      <th>FG MajorLeagueID</th>\n",
       "      <th>FG MinorLeagueID</th>\n",
       "      <th>MLB Org</th>\n",
       "      <th>Position(s)</th>\n",
       "      <th>Avg Salary</th>\n",
       "      <th>Median Salary</th>\n",
       "      <th>Min Salary</th>\n",
       "      <th>Max Salary</th>\n",
       "      <th>...</th>\n",
       "      <th>POS</th>\n",
       "      <th>ADP</th>\n",
       "      <th>rPTS</th>\n",
       "      <th>PTS</th>\n",
       "      <th>aPOS</th>\n",
       "      <th>Dollars</th>\n",
       "      <th>Adjusted</th>\n",
       "      <th>Cost</th>\n",
       "      <th>PlayerId</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Juan Soto</td>\n",
       "      <td>23717</td>\n",
       "      <td>20123.0</td>\n",
       "      <td>sa906282</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>60.31</td>\n",
       "      <td>60.0</td>\n",
       "      <td>34</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>10.57</td>\n",
       "      <td>1132.535865</td>\n",
       "      <td>53.429347</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>76.314969</td>\n",
       "      <td>112.280793</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20123</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mookie Betts</td>\n",
       "      <td>18276</td>\n",
       "      <td>13611.0</td>\n",
       "      <td>sa597889</td>\n",
       "      <td>LAD</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>58.35</td>\n",
       "      <td>58.0</td>\n",
       "      <td>38</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>2B/SS/OF</td>\n",
       "      <td>5.03</td>\n",
       "      <td>1036.172159</td>\n",
       "      <td>40.095221</td>\n",
       "      <td>14.934803</td>\n",
       "      <td>56.030024</td>\n",
       "      <td>82.308998</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13611</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Shohei Ohtani</td>\n",
       "      <td>33600</td>\n",
       "      <td>19755.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LAD</td>\n",
       "      <td>Util/SP</td>\n",
       "      <td>56.13</td>\n",
       "      <td>56.0</td>\n",
       "      <td>32</td>\n",
       "      <td>88</td>\n",
       "      <td>...</td>\n",
       "      <td>P/DH</td>\n",
       "      <td>12.73</td>\n",
       "      <td>1038.276653</td>\n",
       "      <td>40.386426</td>\n",
       "      <td>12.178202</td>\n",
       "      <td>53.564628</td>\n",
       "      <td>75.049219</td>\n",
       "      <td>54.0</td>\n",
       "      <td>19755</td>\n",
       "      <td>-0.435372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Judge</td>\n",
       "      <td>18312</td>\n",
       "      <td>15640.0</td>\n",
       "      <td>sa549847</td>\n",
       "      <td>NYY</td>\n",
       "      <td>OF</td>\n",
       "      <td>54.17</td>\n",
       "      <td>54.5</td>\n",
       "      <td>33</td>\n",
       "      <td>70</td>\n",
       "      <td>...</td>\n",
       "      <td>OF/DH</td>\n",
       "      <td>11.16</td>\n",
       "      <td>1066.255227</td>\n",
       "      <td>44.257902</td>\n",
       "      <td>21.885623</td>\n",
       "      <td>67.143525</td>\n",
       "      <td>93.070498</td>\n",
       "      <td>50.0</td>\n",
       "      <td>15640</td>\n",
       "      <td>17.143525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Freddie Freeman</td>\n",
       "      <td>5680</td>\n",
       "      <td>5361.0</td>\n",
       "      <td>sa390291</td>\n",
       "      <td>LAD</td>\n",
       "      <td>1B</td>\n",
       "      <td>50.76</td>\n",
       "      <td>51.0</td>\n",
       "      <td>27</td>\n",
       "      <td>74</td>\n",
       "      <td>...</td>\n",
       "      <td>1B</td>\n",
       "      <td>8.81</td>\n",
       "      <td>1062.235872</td>\n",
       "      <td>43.701733</td>\n",
       "      <td>13.809086</td>\n",
       "      <td>58.510819</td>\n",
       "      <td>81.663561</td>\n",
       "      <td>47.0</td>\n",
       "      <td>5361</td>\n",
       "      <td>11.510819</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Name  OttoneuID  FG MajorLeagueID FG MinorLeagueID MLB Org  \\\n",
       "0        Juan Soto      23717           20123.0         sa906282     NYY   \n",
       "1     Mookie Betts      18276           13611.0         sa597889     LAD   \n",
       "2    Shohei Ohtani      33600           19755.0              NaN     LAD   \n",
       "3      Aaron Judge      18312           15640.0         sa549847     NYY   \n",
       "4  Freddie Freeman       5680            5361.0         sa390291     LAD   \n",
       "\n",
       "  Position(s)  Avg Salary  Median Salary  Min Salary  Max Salary  ...  \\\n",
       "0          OF       60.31           60.0          34          84  ...   \n",
       "1    2B/SS/OF       58.35           58.0          38          87  ...   \n",
       "2     Util/SP       56.13           56.0          32          88  ...   \n",
       "3          OF       54.17           54.5          33          70  ...   \n",
       "4          1B       50.76           51.0          27          74  ...   \n",
       "\n",
       "        POS    ADP         rPTS        PTS       aPOS    Dollars    Adjusted  \\\n",
       "0     OF/DH  10.57  1132.535865  53.429347  21.885623  76.314969  112.280793   \n",
       "1  2B/SS/OF   5.03  1036.172159  40.095221  14.934803  56.030024   82.308998   \n",
       "2      P/DH  12.73  1038.276653  40.386426  12.178202  53.564628   75.049219   \n",
       "3     OF/DH  11.16  1066.255227  44.257902  21.885623  67.143525   93.070498   \n",
       "4        1B   8.81  1062.235872  43.701733  13.809086  58.510819   81.663561   \n",
       "\n",
       "   Cost  PlayerId      value  \n",
       "0   NaN     20123   0.000000  \n",
       "1   NaN     13611   0.000000  \n",
       "2  54.0     19755  -0.435372  \n",
       "3  50.0     15640  17.143525  \n",
       "4  47.0      5361  11.510819  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orig_df = pd.DataFrame(df)\n",
    "orig_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f44894-6694-4e60-8920-06a7b7e1c971",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['OttoneuID', 'FG MajorLeagueID', 'Avg Salary', 'Median Salary', 'Min Salary', 'Max Salary', 'Last 10', 'Roster%', 'ADP', 'rPTS', 'PTS', 'aPOS', 'Dollars', 'Adjusted', 'Cost', 'value']\n",
      "Categorical features: ['Name', 'FG MinorLeagueID', 'MLB Org', 'Position(s)', 'Team', 'POS', 'PlayerId']\n"
     ]
    }
   ],
   "source": [
    "# Selecting numeric and categorical features\n",
    "numeric_features = orig_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "categorical_features = orig_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {numeric_features}\")\n",
    "print(f\"Categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4aba124b-fd94-4cb0-bad7-f76d82d126da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformers\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('encoder', OneHotEncoder())\n",
    "])\n",
    "\n",
    "# Combine transformers into a preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a2f5ec2-88f6-466c-b625-112fb1dab778",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of prepared_data: (909, 2901)\n"
     ]
    }
   ],
   "source": [
    "# Fit and transform the data\n",
    "prepared_data = preprocessor.fit_transform(orig_df)\n",
    "\n",
    "# Check if the data is sparse and convert to dense if necessary\n",
    "if hasattr(prepared_data, \"toarray\"):\n",
    "    prepared_data = prepared_data.toarray()\n",
    "\n",
    "# Check the shape of the prepared data\n",
    "print(f\"Shape of prepared_data: {prepared_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "82b9ab47-38fa-42b1-93fa-269c84886d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of columns in prepared_data: 2901\n",
      "Number of column names: 2901\n"
     ]
    }
   ],
   "source": [
    "# Get the column names from the transformers\n",
    "numeric_column_names = numeric_features\n",
    "categorical_column_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)\n",
    "\n",
    "# Combine all column names\n",
    "all_column_names = numeric_column_names + list(categorical_column_names)\n",
    "\n",
    "# Verify the lengths match\n",
    "print(f\"Number of columns in prepared_data: {prepared_data.shape[1]}\")\n",
    "print(f\"Number of column names: {len(all_column_names)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "05ca3f87-dfbd-4f6d-a3ba-827546ff93ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   OttoneuID  FG MajorLeagueID  Avg Salary  Median Salary  Min Salary  \\\n",
      "0  -0.209873          0.247488    6.930061       6.916505    8.003330   \n",
      "1  -0.753909         -0.833026    6.678714       6.660718    9.023420   \n",
      "2   0.778310          0.186427    6.394025       6.404932    7.493285   \n",
      "3  -0.750309         -0.496361    6.142677       6.213092    7.748307   \n",
      "4  -2.013360         -2.201921    5.705385       5.765466    6.218172   \n",
      "\n",
      "   Max Salary   Last 10   Roster%       ADP      rPTS  ...  \\\n",
      "0    4.873362  5.999952  1.375820 -1.621671  3.108094  ...   \n",
      "1    5.083293  6.062393  1.375820 -1.640549  2.692647  ...   \n",
      "2    5.153270  5.302691  1.343176 -1.614311  2.701720  ...   \n",
      "3    3.893686  5.042520  1.449258 -1.619661  2.822342  ...   \n",
      "4    4.173594  4.397294  1.392143 -1.627668  2.805014  ...   \n",
      "\n",
      "   PlayerId_sa3020241  PlayerId_sa3022654  PlayerId_sa3022882  \\\n",
      "0                 0.0                 0.0                 0.0   \n",
      "1                 0.0                 0.0                 0.0   \n",
      "2                 0.0                 0.0                 0.0   \n",
      "3                 0.0                 0.0                 0.0   \n",
      "4                 0.0                 0.0                 0.0   \n",
      "\n",
      "   PlayerId_sa3023079  PlayerId_sa3023345  PlayerId_sa3023346  \\\n",
      "0                 0.0                 0.0                 0.0   \n",
      "1                 0.0                 0.0                 0.0   \n",
      "2                 0.0                 0.0                 0.0   \n",
      "3                 0.0                 0.0                 0.0   \n",
      "4                 0.0                 0.0                 0.0   \n",
      "\n",
      "   PlayerId_sa3023348  PlayerId_sa3023349  PlayerId_sa875163  \\\n",
      "0                 0.0                 0.0                0.0   \n",
      "1                 0.0                 0.0                0.0   \n",
      "2                 0.0                 0.0                0.0   \n",
      "3                 0.0                 0.0                0.0   \n",
      "4                 0.0                 0.0                0.0   \n",
      "\n",
      "   PlayerId_sa917333  \n",
      "0                0.0  \n",
      "1                0.0  \n",
      "2                0.0  \n",
      "3                0.0  \n",
      "4                0.0  \n",
      "\n",
      "[5 rows x 2901 columns]\n"
     ]
    }
   ],
   "source": [
    "# Ensure the lengths match before creating the DataFrame\n",
    "if prepared_data.shape[1] == len(all_column_names):\n",
    "    prepared_df = pd.DataFrame(prepared_data, columns=all_column_names)\n",
    "    print(prepared_df.head())\n",
    "else:\n",
    "    raise ValueError(\"The number of columns in the prepared data does not match the number of column names.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d615d3-8d2c-4f53-b174-6dbdb1b04a86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/threadpoolctl.py:1214: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m ctgan \u001b[38;5;241m=\u001b[39m CTGAN(epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)  \u001b[38;5;66;03m# Adjust the number of epochs as needed\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Train the CTGAN model\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mctgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcategorical_column_names\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ctgan/synthesizers/base.py:50\u001b[0m, in \u001b[0;36mrandom_state.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 50\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m set_random_states(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrandom_states, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_random_state):\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ctgan/synthesizers/ctgan.py:306\u001b[0m, in \u001b[0;36mCTGAN.fit\u001b[0;34m(self, train_data, discrete_columns, epochs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer \u001b[38;5;241m=\u001b[39m DataTransformer()\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39mfit(train_data, discrete_columns)\n\u001b[0;32m--> 306\u001b[0m train_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_sampler \u001b[38;5;241m=\u001b[39m DataSampler(\n\u001b[1;32m    309\u001b[0m     train_data,\n\u001b[1;32m    310\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39moutput_info_list,\n\u001b[1;32m    311\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_log_frequency)\n\u001b[1;32m    313\u001b[0m data_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transformer\u001b[38;5;241m.\u001b[39moutput_dimensions\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ctgan/data_transformer.py:183\u001b[0m, in \u001b[0;36mDataTransformer.transform\u001b[0;34m(self, raw_data)\u001b[0m\n\u001b[1;32m    178\u001b[0m     column_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_synchronous_transform(\n\u001b[1;32m    179\u001b[0m         raw_data,\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_column_transform_info_list\n\u001b[1;32m    181\u001b[0m     )\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 183\u001b[0m     column_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parallel_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[43m        \u001b[49m\u001b[43mraw_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    185\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_column_transform_info_list\u001b[49m\n\u001b[1;32m    186\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mconcatenate(column_data_list, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/ctgan/data_transformer.py:167\u001b[0m, in \u001b[0;36mDataTransformer._parallel_transform\u001b[0;34m(self, raw_data, column_transform_info_list)\u001b[0m\n\u001b[1;32m    164\u001b[0m         process \u001b[38;5;241m=\u001b[39m delayed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform_discrete)(column_transform_info, data)\n\u001b[1;32m    165\u001b[0m     processes\u001b[38;5;241m.\u001b[39mappend(process)\n\u001b[0;32m--> 167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocesses\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Initialize the CTGAN model\n",
    "ctgan = CTGAN(epochs=2)  # Adjust the number of epochs as needed\n",
    "\n",
    "# Train the CTGAN model\n",
    "ctgan.fit(prepared_df, categorical_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19db12a-6362-4465-8a5d-f77143db17cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_data(file_path, additional_rows, epochs=5, output_file='synthetic_data_ctgan.csv'):\n",
    "    # Load the original dataset\n",
    "    original_df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Selecting numeric and categorical features\n",
    "    numeric_features = original_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_features = original_df.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "    # Define transformers\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "    ])\n",
    "\n",
    "    # Combine transformers into a preprocessor\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, numeric_features),\n",
    "            ('cat', categorical_transformer, categorical_features)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Fit and transform the data\n",
    "    prepared_data = preprocessor.fit_transform(original_df)\n",
    "\n",
    "    # Check if the data is sparse and convert to dense if necessary\n",
    "    if hasattr(prepared_data, \"toarray\"):\n",
    "        prepared_data = prepared_data.toarray()\n",
    "\n",
    "    # Get the column names from the transformers\n",
    "    numeric_column_names = numeric_features\n",
    "    categorical_column_names = preprocessor.named_transformers_['cat']['encoder'].get_feature_names_out(categorical_features)\n",
    "\n",
    "    # Combine all column names\n",
    "    all_column_names = numeric_column_names + list(categorical_column_names)\n",
    "\n",
    "    # Ensure the lengths match before creating the DataFrame\n",
    "    if prepared_data.shape[1] == len(all_column_names):\n",
    "        prepared_df = pd.DataFrame(prepared_data, columns=all_column_names)\n",
    "    else:\n",
    "        raise ValueError(\"Mismatch between prepared data columns and column names.\")\n",
    "\n",
    "    # Initialize the CTGAN model\n",
    "    ctgan = CTGAN(epochs=epochs)\n",
    "\n",
    "    # Train the CTGAN model\n",
    "    ctgan.fit(prepared_df, categorical_column_names)\n",
    "\n",
    "    # Specify the number of synthetic samples to generate\n",
    "    num_samples = len(original_df) + additional_rows\n",
    "\n",
    "    # Generate synthetic data and measure time taken\n",
    "    start_time = time.time()\n",
    "    synthetic_data = ctgan.sample(num_samples)\n",
    "    elapsed_time = time.time() - start_time\n",
    "\n",
    "    # Convert synthetic data to a pandas DataFrame with appropriate column names\n",
    "    synthetic_df = pd.DataFrame(synthetic_data, columns=all_column_names)\n",
    "\n",
    "    # Save the synthetic data to a CSV file\n",
    "    synthetic_df.to_csv(output_file, index=False)\n",
    "    print(f\"Synthetic data written to '{output_file}' successfully with {num_samples} samples.\")\n",
    "    print(f\"Synthetic data generation completed in {elapsed_time:.2f} seconds.\")\n",
    "    \n",
    "    return synthetic_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79079125-524f-44e9-abf3-46ccaae7083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Evaluation Functions\n",
    "def evaluate_fidelity(real_data, synthetic_data, continuous_columns, categorical_columns):\n",
    "    ks_results = {col: ks_2samp(real_data[col], synthetic_data[col]).statistic for col in continuous_columns}\n",
    "    chi_squared_results = {col: chi2_contingency(pd.crosstab(real_data[col], synthetic_data[col]))[:2] for col in categorical_columns}\n",
    "    return {'KS Test': ks_results, 'Chi-Squared Test': chi_squared_results}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c77e43-3f9c-4946-9133-6d63e861f064",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_predictive_performance(real_data, synthetic_data, target_column, test_size=0.3, random_state=42):\n",
    "    X_real = real_data.drop(columns=[target_column])\n",
    "    y_real = real_data[target_column]\n",
    "    X_synthetic = synthetic_data.drop(columns=[target_column])\n",
    "    y_synthetic = synthetic_data[target_column]\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    model.fit(X_synthetic, y_synthetic)\n",
    "    predictions = model.predict(X_real)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_real, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_real, model.predict_proba(X_real)[:, 1]),\n",
    "        'F1 Score': f1_score(y_real, predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37efbda6-0b3c-42f9-96c5-10f391e7e9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def informativeness_test(real_data, synthetic_data, test_size=0.3, random_state=42):\n",
    "    real_data['is_real'] = 1\n",
    "    synthetic_data['is_real'] = 0\n",
    "    combined_data = pd.concat([real_data, synthetic_data], ignore_index=True)\n",
    "    X = combined_data.drop(columns=['is_real'])\n",
    "    y = combined_data['is_real']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    classifier = RandomForestClassifier(n_estimators=100, random_state=random_state)\n",
    "    classifier.fit(X_train, y_train)\n",
    "    predictions = classifier.predict(X_test)\n",
    "    return {\n",
    "        'Accuracy': accuracy_score(y_test, predictions),\n",
    "        'ROC AUC': roc_auc_score(y_test, classifier.predict_proba(X_test)[:, 1]),\n",
    "        'F1 Score': f1_score(y_test, predictions)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2418e7d4-a209-4c57-aa4d-23da4127629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the synthetic data\n",
    "def evaluate_synthetic_data(original_df, synthetic_df, target_column):\n",
    "    # Identify columns to apply metrics\n",
    "    continuous_columns = original_df.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    categorical_columns = original_df.select_dtypes(include=['object']).columns.tolist()\n",
    "\n",
    "    # Evaluate fidelity\n",
    "    fidelity_results = evaluate_fidelity(original_df, synthetic_df, continuous_columns, categorical_columns)\n",
    "    print(\"Fidelity Results:\", fidelity_results)\n",
    "\n",
    "    # Evaluate predictive performance\n",
    "    if target_column in original_df.columns:\n",
    "        predictive_performance_results = evaluate_predictive_performance(original_df, synthetic_df, target_column)\n",
    "        print(\"Predictive Performance Results:\", predictive_performance_results)\n",
    "    else:\n",
    "        print(f\"Error: Target column '{target_column}' does not exist in the DataFrame.\")\n",
    "\n",
    "    # Evaluate informativeness\n",
    "    informativeness_results = informativeness_test(original_df, synthetic_df)\n",
    "    print(\"Informativeness Results:\", informativeness_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e3abf5-8219-4f1d-b17f-a6f01a3f9506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage of the function\n",
    "if __name__ == \"__main__\":\n",
    "    file_path = 'path_to_your_data.csv'  # Update this path to your dataset\n",
    "    additional_rows = int(input(\"Enter the number of additional synthetic data samples to generate: \"))\n",
    "    epochs = int(input(\"Enter the number of epochs for training the CTGAN model: \"))\n",
    "    output_file = input(\"Enter the name of the output file (with .csv extension): \")\n",
    "    \n",
    "    synthetic_df = generate_synthetic_data(file_path, additional_rows, epochs=epochs, output_file=output_file)\n",
    "\n",
    "    # Print some outputs to verify\n",
    "    print(\"Generated synthetic data shape:\", synthetic_df.shape)\n",
    "    print(\"Sample of synthetic data:\")\n",
    "    print(synthetic_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "996b80d2-99a9-4170-9846-83d648ce7959",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    target_column = 'your_target_column'  # Replace with your actual target column name\n",
    "    evaluate_synthetic_data(original_df, synthetic_df, target_column)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
